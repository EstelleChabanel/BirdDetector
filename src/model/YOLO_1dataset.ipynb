{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.0 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-PCIE-40GB, 40338MiB)\n",
      "Setup complete âœ… (36 CPUs, 376.6 GB RAM, 0.1/188.3 GB disk)\n",
      "/vast/palmer/home.grace/eec42/BirdDetector/src\n",
      "/vast/palmer/home.grace/eec42/BirdDetector/src/data_preprocessing\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#import dayolo\n",
    "#from dayolo import YOLO\n",
    "\n",
    "#import yolo\n",
    "#from yolo import YOLO\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import os\n",
    "import random\n",
    "#from ultralytics.utils.plotting import plot_labels\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(module_path)\n",
    "module_path = module_path+'/data_preprocessing'\n",
    "print(module_path)\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#import visualization_utils as visutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "device = \"0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"0\":\n",
    "    torch.cuda.set_device(0) # Set to your desired GPU number\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs/detect/tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mðŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/20 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'scale': 0.5, 'flipud': 0.0, 'fliplr': 0.5}\n",
      "New https://pypi.org/project/ultralytics/8.1.9 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.0 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-PCIE-40GB, 40338MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=80, time=None, patience=50, batch=16, imgsz=640, save=False, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /gpfs/gibbs/project/jetz/eec42/data/pe_palmyra_10percentbkgd/train/labels.cache... 1722 images, 182 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1904/1904 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /gpfs/gibbs/project/jetz/eec42/data/pe_palmyra_10percentbkgd/val/labels.cache... 248 images, 19 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/80      7.06G      2.869      2.494      1.397         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [00:17<00:00,  6.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.98it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        267       1656     0.0401       0.16     0.0188    0.00545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/80      7.19G      2.429      1.864      1.162        107        640:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 64/119 [00:08<00:06,  8.20it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Tune hyperparameters on COCO8 for 30 epochs\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m            \u001b[38;5;66;03m#space={\"lr0\": tune.uniform(1e-5, 1e-1)}, use_ray=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/site-packages/ultralytics/engine/model.py:416\u001b[0m, in \u001b[0;36mModel.tune\u001b[0;34m(self, use_ray, iterations, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m custom \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    415\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/site-packages/ultralytics/engine/tuner.py:194\u001b[0m, in \u001b[0;36mTuner.__call__\u001b[0;34m(self, model, iterations, cleanup)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Train YOLO model with mutated hyperparameters (run in subprocess to avoid dataloader hang)\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m train_args\u001b[38;5;241m.\u001b[39mitems())]\n\u001b[0;32m--> 194\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreturncode\n\u001b[1;32m    195\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ckpt_file)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m return_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/subprocess.py:2046\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2045\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2046\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/.conda/envs/pdm/lib/python3.11/subprocess.py:2004\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2004\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2009\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# Tune hyperparameters on COCO8 for 30 epochs\n",
    "model.tune(data='data.yaml', iterations=20, epochs=80, optimizer='SGD', plots=False, save=False, val=True, workers=8) #,\n",
    "           #space={\"lr0\": tune.uniform(1e-5, 1e-1)}, use_ray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING DOMAIN CLASSIFIER MODEL\n",
      "INITIALIZING DOMAIN CLASSIFIER MODEL\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  yolo.nn.modules.conv.Conv                    [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  yolo.nn.modules.conv.Conv                    [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  yolo.nn.modules.block.C2f                    [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  yolo.nn.modules.conv.Conv                    [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  yolo.nn.modules.block.C2f                    [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  yolo.nn.modules.conv.Conv                    [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  yolo.nn.modules.block.C2f                    [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  yolo.nn.modules.conv.Conv                    [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  yolo.nn.modules.block.C2f                    [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  yolo.nn.modules.block.SPPF                   [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 12                  -1  1    148224  yolo.nn.modules.block.C2f                    [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 15                  -1  1     37248  yolo.nn.modules.block.C2f                    [192, 64, 1]                  \n",
      " 16                  -1  1     36992  yolo.nn.modules.conv.Conv                    [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 18                  -1  1    123648  yolo.nn.modules.block.C2f                    [192, 128, 1]                 \n",
      " 19                  -1  1    147712  yolo.nn.modules.conv.Conv                    [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 21                  -1  1    493056  yolo.nn.modules.block.C2f                    [384, 256, 1]                 \n",
      " 50                   9  1         0  yolo.nn.modules.dan.GradReversal             [1]                           \n",
      " 51                  -1  1    887043  yolo.nn.modules.dan.Conv_                    [256, 256, 128]               \n",
      " 52                  -1  1         4  yolo.nn.modules.dan.AdaptiveAvgPooling       [1]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54        [15, 18, 21]  1    751507  yolo.nn.modules.head.Detect                  [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 239 layers, 3898090 parameters, 3898074 gradients\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  yolo.nn.modules.conv.Conv                    [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  yolo.nn.modules.conv.Conv                    [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  yolo.nn.modules.block.C2f                    [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  yolo.nn.modules.conv.Conv                    [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  yolo.nn.modules.block.C2f                    [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  yolo.nn.modules.conv.Conv                    [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  yolo.nn.modules.block.C2f                    [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  yolo.nn.modules.conv.Conv                    [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  yolo.nn.modules.block.C2f                    [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  yolo.nn.modules.block.SPPF                   [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 12                  -1  2   1993728  yolo.nn.modules.block.C2f                    [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 15                  -1  2    517632  yolo.nn.modules.block.C2f                    [576, 192, 2]                 \n",
      " 16                  -1  1    332160  yolo.nn.modules.conv.Conv                    [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 18                  -1  2   1846272  yolo.nn.modules.block.C2f                    [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  yolo.nn.modules.conv.Conv                    [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 21                  -1  2   4207104  yolo.nn.modules.block.C2f                    [960, 576, 2]                 \n",
      " 54        [15, 18, 21]  1   3776275  yolo.nn.modules.head.Detect                  [1, [192, 384, 576]]          \n",
      "YOLOv8m summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Transferred 469/475 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "# Create a new YOLO model from scratch\n",
    "#model = YOLO('yolov8n.yaml')\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training) - for now, we keep the small version\n",
    "#pretrained_model_name = 'pfeifer_penguins_poland_10percentbckgd_yolov8m_120epoch'\n",
    "#model_path = 'runs/detect/' + pretrained_model_name + '/weights/best.pt'\n",
    "#model = YOLO('yolov8m.pt', task='da_detect')\n",
    "#model = YOLO(\"yolov8.yaml\").load(\"yolov8m.pt\")\n",
    "#model = YOLO('yolov8m.pt', task='da_detect')\n",
    "#model = YOLO('yolov8m.pt', task='detect')\n",
    "#model = YOLO(\"yolov8m.yaml\", task='detect').load(\"yolov8m.pt\")\n",
    "model = YOLO(\"yolov8m.yaml\", task='detect', subtask='unsupervisedmultidomainclassifier').load(\"yolov8m.pt\")\n",
    "\n",
    "\n",
    "#model.load_weights('yolov8m.pt')\n",
    "\n",
    "\n",
    "#PRETRAINED_MODEL_NAME = 'pfeifer_penguins_poland_10percentbckgd_yolov8m_120epoch'\n",
    "#PRETRAINED_MODEL_PATH = 'src/model/runs/detect/' + PRETRAINED_MODEL_NAME + '/weights/best.pt'\n",
    "\n",
    "#MODEL_NAME = 'pfeifer_penguins_poland_palmyra_10percent_bckgd_yolov8m_120epochs'\n",
    "#TASK = 'detect' # Choose between: 'deepcoral_detect' 'detect'\n",
    "#model = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect\n",
      "unsupervisedmultidomainclassifier\n"
     ]
    }
   ],
   "source": [
    "print(model.task)\n",
    "print(model.subtask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 22\n",
      "Detect(\n",
      "  (cv2): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (cv3): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (dfl): DFL(\n",
      "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.model.model\n",
    "for i, a in enumerate(model.model.model):\n",
    "    if i == 22:\n",
    "        print(\"block\", i)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.6 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "New https://pypi.org/project/ultralytics/8.1.6 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=data.yaml, epochs=3, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=TEST_features_loss3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, source_name=global_birds_palmyra, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, dc=1.0, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=90, translate=0.0, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/TEST_features_loss3\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=data.yaml, epochs=3, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=TEST_features_loss3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, source_name=global_birds_palmyra, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, dc=1.0, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=90, translate=0.0, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/TEST_features_loss3\n",
      "INITIALIZING DOMAIN CLASSIFIER MODEL\n",
      "INITIALIZING DOMAIN CLASSIFIER MODEL\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  yolo.nn.modules.conv.Conv                    [3, 16, 3, 2]                 \n",
      "  0                  -1  1       464  yolo.nn.modules.conv.Conv                    [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  yolo.nn.modules.conv.Conv                    [16, 32, 3, 2]                \n",
      "  1                  -1  1      4672  yolo.nn.modules.conv.Conv                    [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  yolo.nn.modules.block.C2f                    [32, 32, 1, True]             \n",
      "  2                  -1  1      7360  yolo.nn.modules.block.C2f                    [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  yolo.nn.modules.conv.Conv                    [32, 64, 3, 2]                \n",
      "  3                  -1  1     18560  yolo.nn.modules.conv.Conv                    [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  yolo.nn.modules.block.C2f                    [64, 64, 2, True]             \n",
      "  4                  -1  2     49664  yolo.nn.modules.block.C2f                    [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  yolo.nn.modules.conv.Conv                    [64, 128, 3, 2]               \n",
      "  5                  -1  1     73984  yolo.nn.modules.conv.Conv                    [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  yolo.nn.modules.block.C2f                    [128, 128, 2, True]           \n",
      "  6                  -1  2    197632  yolo.nn.modules.block.C2f                    [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  yolo.nn.modules.conv.Conv                    [128, 256, 3, 2]              \n",
      "  7                  -1  1    295424  yolo.nn.modules.conv.Conv                    [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  yolo.nn.modules.block.C2f                    [256, 256, 1, True]           \n",
      "  8                  -1  1    460288  yolo.nn.modules.block.C2f                    [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  yolo.nn.modules.block.SPPF                   [256, 256, 5]                 \n",
      "  9                  -1  1    164608  yolo.nn.modules.block.SPPF                   [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 12                  -1  1    148224  yolo.nn.modules.block.C2f                    [384, 128, 1]                 \n",
      " 12                  -1  1    148224  yolo.nn.modules.block.C2f                    [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 15                  -1  1     37248  yolo.nn.modules.block.C2f                    [192, 64, 1]                  \n",
      " 15                  -1  1     37248  yolo.nn.modules.block.C2f                    [192, 64, 1]                  \n",
      " 16                  -1  1     36992  yolo.nn.modules.conv.Conv                    [64, 64, 3, 2]                \n",
      " 16                  -1  1     36992  yolo.nn.modules.conv.Conv                    [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 18                  -1  1    123648  yolo.nn.modules.block.C2f                    [192, 128, 1]                 \n",
      " 18                  -1  1    123648  yolo.nn.modules.block.C2f                    [192, 128, 1]                 \n",
      " 19                  -1  1    147712  yolo.nn.modules.conv.Conv                    [128, 128, 3, 2]              \n",
      " 19                  -1  1    147712  yolo.nn.modules.conv.Conv                    [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 21                  -1  1    493056  yolo.nn.modules.block.C2f                    [384, 256, 1]                 \n",
      " 21                  -1  1    493056  yolo.nn.modules.block.C2f                    [384, 256, 1]                 \n",
      " 50                   9  1         0  yolo.nn.modules.dan.GradReversal             [1]                           \n",
      " 50                   9  1         0  yolo.nn.modules.dan.GradReversal             [1]                           \n",
      " 51                  -1  1    887043  yolo.nn.modules.dan.Conv_                    [256, 256, 128]               \n",
      " 51                  -1  1    887043  yolo.nn.modules.dan.Conv_                    [256, 256, 128]               \n",
      " 52                  -1  1         4  yolo.nn.modules.dan.AdaptiveAvgPooling       [1]                           \n",
      " 52                  -1  1         4  yolo.nn.modules.dan.AdaptiveAvgPooling       [1]                           \n",
      " 54        [15, 18, 21]  1    751507  yolo.nn.modules.head.Detect                  [1, [64, 128, 256]]           \n",
      " 54        [15, 18, 21]  1    751507  yolo.nn.modules.head.Detect                  [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 239 layers, 3898090 parameters, 3898074 gradients\n",
      "YOLOv8n summary: 239 layers, 3898090 parameters, 3898074 gradients\n",
      "\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  yolo.nn.modules.conv.Conv                    [3, 48, 3, 2]                 \n",
      "  0                  -1  1      1392  yolo.nn.modules.conv.Conv                    [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  yolo.nn.modules.conv.Conv                    [48, 96, 3, 2]                \n",
      "  1                  -1  1     41664  yolo.nn.modules.conv.Conv                    [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  yolo.nn.modules.block.C2f                    [96, 96, 2, True]             \n",
      "  2                  -1  2    111360  yolo.nn.modules.block.C2f                    [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  yolo.nn.modules.conv.Conv                    [96, 192, 3, 2]               \n",
      "  3                  -1  1    166272  yolo.nn.modules.conv.Conv                    [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  yolo.nn.modules.block.C2f                    [192, 192, 4, True]           \n",
      "  4                  -1  4    813312  yolo.nn.modules.block.C2f                    [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  yolo.nn.modules.conv.Conv                    [192, 384, 3, 2]              \n",
      "  5                  -1  1    664320  yolo.nn.modules.conv.Conv                    [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  yolo.nn.modules.block.C2f                    [384, 384, 4, True]           \n",
      "  6                  -1  4   3248640  yolo.nn.modules.block.C2f                    [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  yolo.nn.modules.conv.Conv                    [384, 576, 3, 2]              \n",
      "  7                  -1  1   1991808  yolo.nn.modules.conv.Conv                    [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  yolo.nn.modules.block.C2f                    [576, 576, 2, True]           \n",
      "  8                  -1  2   3985920  yolo.nn.modules.block.C2f                    [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  yolo.nn.modules.block.SPPF                   [576, 576, 5]                 \n",
      "  9                  -1  1    831168  yolo.nn.modules.block.SPPF                   [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 11             [-1, 6]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 12                  -1  2   1993728  yolo.nn.modules.block.C2f                    [960, 384, 2]                 \n",
      " 12                  -1  2   1993728  yolo.nn.modules.block.C2f                    [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 14             [-1, 4]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 15                  -1  2    517632  yolo.nn.modules.block.C2f                    [576, 192, 2]                 \n",
      " 15                  -1  2    517632  yolo.nn.modules.block.C2f                    [576, 192, 2]                 \n",
      " 16                  -1  1    332160  yolo.nn.modules.conv.Conv                    [192, 192, 3, 2]              \n",
      " 16                  -1  1    332160  yolo.nn.modules.conv.Conv                    [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 17            [-1, 12]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 18                  -1  2   1846272  yolo.nn.modules.block.C2f                    [576, 384, 2]                 \n",
      " 18                  -1  2   1846272  yolo.nn.modules.block.C2f                    [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  yolo.nn.modules.conv.Conv                    [384, 384, 3, 2]              \n",
      " 19                  -1  1   1327872  yolo.nn.modules.conv.Conv                    [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 20             [-1, 9]  1         0  yolo.nn.modules.conv.Concat                  [1]                           \n",
      " 21                  -1  2   4207104  yolo.nn.modules.block.C2f                    [960, 576, 2]                 \n",
      " 21                  -1  2   4207104  yolo.nn.modules.block.C2f                    [960, 576, 2]                 \n",
      " 54        [15, 18, 21]  1   3776275  yolo.nn.modules.head.Detect                  [1, [192, 384, 576]]          \n",
      " 54        [15, 18, 21]  1   3776275  yolo.nn.modules.head.Detect                  [1, [192, 384, 576]]          \n",
      "YOLOv8m summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "YOLOv8m summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
      "\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /gpfs/gibbs/project/jetz/eec42/data/pe_10percent_background_unsupervised/train/source/labels.cache... 626 images, 62 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 688/688 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /gpfs/gibbs/project/jetz/eec42/data/pe_10percent_background_unsupervised/train/target/labels.cache... 1096 images, 104 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /gpfs/gibbs/project/jetz/eec42/data/pe_10percent_background_unsupervised/val/labels.cache... 82 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:00<?, ?it/s]\n",
      "/home/eec42/.conda/envs/pdm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/TEST_features_loss3/labels.jpg... \n",
      "Plotting labels to runs/detect/TEST_features_loss3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "3 epochs...\n",
      "3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3        11G      2.508      2.621      1.327     0.7487     0.7073     0.7188         85        640:   0%|          | 0/150 [00:19<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3      10.6G      2.288      1.633      1.206     0.7502     0.7073     0.7261         84        640:   0%|          | 0/150 [00:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  da_loss_s  da_loss_m  da_loss_l  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.74it/s][00:16<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84       1351      0.599      0.661      0.579      0.122\n",
      "                   all         84       1351      0.599      0.661      0.579      0.122\n",
      "\n",
      "3 epochs completed in 0.016 hours.\n",
      "\n",
      "3 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from runs/detect/TEST_features_loss3/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/TEST_features_loss3/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/TEST_features_loss3/weights/best.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/TEST_features_loss3/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/TEST_features_loss3/weights/best.pt...\n",
      "\n",
      "Validating runs/detect/TEST_features_loss3/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.11.6 torch-2.1.0+cu121 CUDA:0 (NVIDIA RTX A5000, 24248MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "YOLOv8m summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84       1351      0.601      0.659      0.579      0.122\n",
      "                   all         84       1351      0.601      0.659      0.579      0.122\n",
      "Speed: 0.1ms preprocess, 6.0ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Speed: 0.1ms preprocess, 6.0ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/TEST_features_loss3\u001b[0m\n",
      "Results saved to \u001b[1mruns/detect/TEST_features_loss3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      11.9G       2.16      1.465      1.174     0.7505     0.7073     0.7287        110        640:   0%|          | 0/150 [00:28<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRAIN the model on our dataset (data.yml config file) \n",
    "\n",
    "model_name = 'TEST_features_loss'\n",
    "\n",
    "results = model.train(\n",
    "   data='data.yaml',\n",
    "   #imgsz=480,  # we are trying with several img size so we do not precise the size -> will automatically resize all images to 640x640\n",
    "   epochs=3,\n",
    "   batch=8, #32,\n",
    "   #cos_lr=True,\n",
    "   #dropout=0.3,\n",
    "   #optimizer='Adam',\n",
    "   patience=10,\n",
    "   device=0,\n",
    "   verbose=True,\n",
    "   val = False,\n",
    "   #lr0=0.001,\n",
    "   #lrf=0.0001,\n",
    "   degrees=90, fliplr=0.5, flipud=0.5, scale=0.5, # augmentation parameters\n",
    "   name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx = torch.Tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 3., 3., 4., 5., 6., 7.])\n",
    "annotations_mask = [False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False]\n",
    "\n",
    "new_batch_idx = batch_idx[annotations_mask]\n",
    "new_batch_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = new_batch_idx.unique(return_inverse=True)\n",
    "b[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0: 640x640 (no detections), 1: 640x640 94 birds, 2: 640x640 1 bird, 3: 640x640 3 birds, 4: 640x640 (no detections), 111.5ms\n",
      "0: 640x640 (no detections), 1: 640x640 94 birds, 2: 640x640 1 bird, 3: 640x640 3 birds, 4: 640x640 (no detections), 111.5ms\n",
      "Speed: 1.3ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.3ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_img = []\n",
    "img_path = '/gpfs/gibbs/project/jetz/eec42/data/pe_palmyra_10percentbkgd/test/'\n",
    "selected_img.extend(random.choices(os.listdir(img_path + '/images/'), k=5))\n",
    "\n",
    "# Predict results for randomly selected images\n",
    "results = model.predict(\n",
    "        #model = 'runs/detect/pfeifer_yolov8n_70epoch_default_batch32_dropout0.3',\n",
    "        source = [os.path.join(img_path + 'images/', img) for img in selected_img],\n",
    "        conf = 0.1, \n",
    "        iou = 0.1,\n",
    "        show = False,\n",
    "        save = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.model\n",
    "for i, a in enumerate(model.model.model):\n",
    "    if i == 23:\n",
    "        print(\"block\", i)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsupervisedmultidomainclassifier'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.subtask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mB\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vast/palmer/home.grace/eec42/BirdDetector\n",
      "/vast/palmer/home.grace/eec42/BirdDetector/runs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..'))\n",
    "print(module_path)\n",
    "module_path = module_path+'/runs'\n",
    "print(module_path)\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_PATH = module_path + '/detect/YOLO_pe_palmyra_10percentbkgd_test2/weights/best.pt'\n",
    "model = YOLO('yolov8m.yaml', task='detect').load(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 (no detections), 4: 640x640 (no detections), 5: 640x640 (no detections), 6: 640x640 (no detections), 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 (no detections), 11: 640x640 (no detections), 12: 640x640 (no detections), 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 (no detections), 16: 640x640 (no detections), 17: 640x640 (no detections), 18: 640x640 (no detections), 19: 640x640 (no detections), 196.3ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "selected_img = []\n",
    "img_path = '/gpfs/gibbs/project/jetz/eec42/data/pe_palmyra_10percentbkgd/test/'\n",
    "for subdataset in ['global_birds_penguins', 'global_birds_palmyra']:\n",
    "    selected_img.extend(random.choices(os.listdir(img_path + subdataset + '/images/'), k=10))\n",
    "\n",
    "results = model.predict(\n",
    "        #model = 'runs/detect/pfeifer_yolov8n_70epoch_default_batch32_dropout0.3',\n",
    "        source = [os.path.join(img_path + 'images/', img) for img in selected_img],\n",
    "        conf = 0.1, \n",
    "        iou = 0.1,\n",
    "        show = False,\n",
    "        save = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([], device='cuda:0')\n",
       "conf: tensor([], device='cuda:0')\n",
       "data: tensor([], device='cuda:0', size=(0, 6))\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (480, 480)\n",
       "shape: torch.Size([0, 6])\n",
       "xywh: tensor([], device='cuda:0', size=(0, 4))\n",
       "xywhn: tensor([], device='cuda:0', size=(0, 4))\n",
       "xyxy: tensor([], device='cuda:0', size=(0, 4))\n",
       "xyxyn: tensor([], device='cuda:0', size=(0, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5].boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'deepcoral_detect' #detect\n",
    "#model_name = 'deepcoral_test4'\n",
    "#model_path = 'runs/' + TASK + '/' + model_name + '/weights/best.pt'\n",
    "#model = YOLO(model_path, TASK)\n",
    "model_name = 'deepcoral_background_lscale16_epochs20_coralgain10'\n",
    "PRETRAINED_MODEL_PATH = 'runs/' + TASK + '/' + model_name + '/weights/best.pt'\n",
    "\n",
    "model = YOLO(PRETRAINED_MODEL_PATH, TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['source', 'target'] #['global_birds_poland', 'global_birds_palmyra', 'global_birds_penguins', 'global_birds_pfeifer']\n",
    "fname = \"data.yaml\"\n",
    "stream = open(fname, 'r')\n",
    "data = yaml.safe_load(stream)\n",
    "img_path = data['path'] + '/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NORMAL MODEL\n",
    "# Select randomly 10 images from the test dataset\n",
    "\n",
    "if TASK == 'detect':\n",
    "    selected_img = []\n",
    "    for subdataset in datasets:\n",
    "        selected_img.extend(random.choices(os.listdir(img_path + subdataset + '/images/'), k=6))\n",
    "\n",
    "    results = model.predict(\n",
    "            #model = 'runs/detect/pfeifer_yolov8n_70epoch_default_batch32_dropout0.3',\n",
    "            source = [os.path.join(img_path + 'images/', img) for img in selected_img],\n",
    "            conf = 0.2, \n",
    "            iou = 0.1,\n",
    "            show=False,\n",
    "            save=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == 'detect':\n",
    "    for img, result in zip(selected_img, results):\n",
    "\n",
    "        detection_boxes = []\n",
    "        save_path = '/vast/palmer/home.grace/eec42/BirdDetector/src/model/runs/detect/' + model_name + '/prediction_' + os.path.basename(result.path).split('.jpg')[0] + '.jpg'\n",
    "        for detect in range(len(result.boxes.cls)):\n",
    "            det = {}\n",
    "            det['conf'] = result.boxes.conf[detect].cpu()\n",
    "            det['category'] = result.boxes.cls[detect].cpu()\n",
    "            coords = result.boxes.xywhn[detect].cpu()\n",
    "            det['bbox'] = [coords[0]-coords[2]/2, coords[1]-coords[3]/2, coords[2], coords[3]]\n",
    "            detection_boxes.append(det)\n",
    "            \n",
    "        im_path = os.path.join(img_path + 'images/', img)\n",
    "        visutils.draw_bounding_boxes_on_file(im_path, save_path, detection_boxes,\n",
    "                                        confidence_threshold=0.0, detector_label_map=None,\n",
    "                                        thickness=1,expansion=0, colormap=['Red'])\n",
    "\n",
    "        selected_label = img_path + 'labels/' + os.path.basename(result.path).split('.jpg')[0] + '.txt'\n",
    "        if os.path.exists(selected_label):\n",
    "            detection_boxes = []\n",
    "            df = pd.read_csv(selected_label, sep='\\t', header=None, index_col=False)\n",
    "            for irow, row in df.iterrows():  \n",
    "                det = {}\n",
    "                det['conf'] = None\n",
    "                det['category'] = row[0]\n",
    "                det['bbox'] = [row[1]-row[3]/2, row[2]-row[4]/2, row[3], row[4]]\n",
    "                detection_boxes.append(det)\n",
    "        \n",
    "            # Draw annotations\n",
    "            save_path2 = '/vast/palmer/home.grace/eec42/BirdDetector/src/model/runs/detect/' + model_name + '/prediction_label_' + os.path.basename(result.path).split('.hpg')[0] + '.jpg'\n",
    "            visutils.draw_bounding_boxes_on_file(save_path, save_path2, detection_boxes,\n",
    "                                            confidence_threshold=0.0, detector_label_map=None,\n",
    "                                            thickness=1,expansion=0, colormap=['SpringGreen'])\n",
    "                                            \n",
    "            # Remove predictions-only images\n",
    "            os.remove(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEEP CORAL MODEL\n",
    "# Select randomly 10 images from the test dataset\n",
    "\n",
    "if TASK == 'deepcoral_detect':\n",
    "\n",
    "    for subdataset in datasets:\n",
    "        selected_img = random.choices(os.listdir(img_path + subdataset + '/images/'), k=12)\n",
    "\n",
    "        results = model.predict(\n",
    "                #model = 'runs/detect/pfeifer_yolov8n_70epoch_default_batch32_dropout0.3',\n",
    "                source = [os.path.join(img_path, subdataset + '/images/', img) for img in selected_img],\n",
    "                conf = 0.2, \n",
    "                iou = 0.1,\n",
    "                show=False,\n",
    "                save=False\n",
    "            )\n",
    "        \n",
    "        for img, result in zip(selected_img, results):\n",
    "\n",
    "            detection_boxes = []\n",
    "            save_path = '/vast/palmer/home.grace/eec42/BirdDetector/src/model/runs/' + TASK + '/' + model_name + '/prediction_' + os.path.basename(result.path).split('.jpg')[0] + '.jpg'\n",
    "            for detect in range(len(result.boxes.cls)):\n",
    "                det = {}\n",
    "                det['conf'] = result.boxes.conf[detect].cpu()\n",
    "                det['category'] = result.boxes.cls[detect].cpu()\n",
    "                coords = result.boxes.xywhn[detect].cpu()\n",
    "                det['bbox'] = [coords[0]-coords[2]/2, coords[1]-coords[3]/2, coords[2], coords[3]]\n",
    "                detection_boxes.append(det)\n",
    "                \n",
    "            im_path = os.path.join(img_path + subdataset + '/images/', img)\n",
    "            visutils.draw_bounding_boxes_on_file(im_path, save_path, detection_boxes,\n",
    "                                            confidence_threshold=0.0, detector_label_map=None,\n",
    "                                            thickness=1,expansion=0, colormap=['Red'])\n",
    "\n",
    "            selected_label = img_path  + subdataset + '/labels/' + os.path.basename(result.path).split('.jpg')[0] + '.txt'\n",
    "            if os.path.exists(selected_label):\n",
    "                detection_boxes = []\n",
    "                df = pd.read_csv(selected_label, sep='\\t', header=None, index_col=False)\n",
    "                for irow, row in df.iterrows():  \n",
    "                    det = {}\n",
    "                    det['conf'] = None\n",
    "                    det['category'] = row[0]\n",
    "                    det['bbox'] = [row[1]-row[3]/2, row[2]-row[4]/2, row[3], row[4]]\n",
    "                    detection_boxes.append(det)\n",
    "        \n",
    "                # Draw annotations\n",
    "                save_path2 = '/vast/palmer/home.grace/eec42/BirdDetector/src/model/runs/' + TASK + '/' + model_name + '/prediction_label_' + os.path.basename(result.path).split('.hpg')[0] + '.jpg'\n",
    "                visutils.draw_bounding_boxes_on_file(save_path, save_path2, detection_boxes,\n",
    "                                                confidence_threshold=0.0, detector_label_map=None,\n",
    "                                                thickness=1,expansion=0, colormap=['SpringGreen'])\n",
    "                \n",
    "                # Remove predictions-only images\n",
    "                os.remove(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE the model's performance on the test set\n",
    "metrics = model.val(split='test', save_json=True, iou=0.1, conf=0.2, max_det=600)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "#success = model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.box.map)\n",
    "print(metrics.box.map50)    # map50-95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Evaluation per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =  ['global_birds_poland', 'global_birds_palmyra', 'global_birds_penguins',\n",
    "                    'global_birds_mckellar', 'global_birds_newmexico', \n",
    "                    'global_birds_pfeifer', 'uav_thermal_waterfowl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pfeifer_penguins_poland_palmyra_mckellar_yolov8m_120epoch'\n",
    "model = YOLO('runs/detect/' + model_name + '/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "\n",
    "    # Change test folder\n",
    "    fname = \"data.yaml\"\n",
    "    stream = open(fname, 'r')\n",
    "    data = yaml.safe_load(stream)\n",
    "    data['test'] = 'test/' + dataset + '/images/'\n",
    "    with open(fname, 'w') as yaml_file:\n",
    "        yaml_file.write( yaml.dump(data, default_flow_style=False))\n",
    "    \n",
    "    metrics = model.val(split='test', save_json=True, iou=0.1, max_det=600)\n",
    "    print(metrics.box.map50)\n",
    "\n",
    "# Change test folder to original name\n",
    "fname = \"data.yaml\"\n",
    "stream = open(fname, 'r')\n",
    "data = yaml.safe_load(stream)\n",
    "data['test'] = 'test/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pfeifer_yolov8m_120epoch_default_batch32_aug90deg0.5flips_patience50_lr00.001_lrf0.0001'\n",
    "model = YOLO('runs/detect/' + model_name + '/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data.yaml\"\n",
    "stream = open(fname, 'r')\n",
    "data = yaml.safe_load(stream)\n",
    "img_path = data['path'] + '/test/'\n",
    "\n",
    "selected_img = (random.choices(os.listdir(img_path + '/images/'), k=1))\n",
    "selected_img = [os.path.join(img_path + '/images/', x) for x in selected_img]\n",
    "selected_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(selected_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
